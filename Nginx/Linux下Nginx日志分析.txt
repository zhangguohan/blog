
Linux下Nginx日志分析


摘要 ：Linux下使用shell语句以Nginx访问日志access_log日志分析为例进行分析。

以Nginx访问日志access_log日志分析为例，使用默认格式：

[TOC]

log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
                  '$status $body_bytes_sent "$http_referer" '
                  '"$http_user_agent" "$http_x_forwarded_for"';

各字段的含义分别是：

        $server_name：虚拟主机名称。
        $remote_addr：远程客户端的IP地址，请求者IP。
        -：空白，用一个“-”占位符替代，历史原因导致还存在。
        $remote_user：远程客户端用户名称，用于记录浏览者进行身份验证时提供的名字，如登录百度的用户名scq2099yt，如果没有登录就是空白。
        [$time_local]：访问的时间与时区，比如07/Jun/2016:08:54:27 +0800，时间信息最后的"+0800"表示服务器所处时区位于UTC之后的8小时。
        $request：请求的URI和HTTP协议，这是整个PV日志记录中最有用的信息，记录服务器收到一个什么样的请求
        $status：记录请求返回的http状态码，比如成功是200。
        $uptream_status：upstream状态，比如成功是200.
        $body_bytes_sent：发送给客户端的文件主体内容的大小，比如899，可以将日志每条记录中的这个值累加起来以粗略估计服务器吞吐量。
        $http_referer：记录从哪个页面链接访问过来的。
        $http_user_agent：客户端浏览器信息
        $http_x_forwarded_for：客户端的真实ip，通常web服务器放在反向代理的后面，这样就不能获取到客户的IP地址了，通过$remote_add拿到的IP地址是反向代理服务器的iP地址。反向代理服务器在转发请求的http头信息中，可以增加x_forwarded_for信息，用以记录原有客户端的IP地址和原来客户端的请求的服务器地址。
        $ssl_protocol：SSL协议版本，比如TLSv1。
        $ssl_cipher：交换数据中的算法，比如RC4-SHA。
        $upstream_addr：upstream的地址，即真正提供服务的主机地址。
        $request_time：整个请求的总时间。
        $upstream_response_time：请求过程中，upstream的响应时间。

根据状态码进行请求次数排序

cat access.log | cut -d '"' -f3 | cut -d ' ' -f2| sort | uniq -c | sort -rn

或者使用awk进行统计。

awk '{print $9}' access.log | sort | uniq -c | sort -rn

输出如下：

 186217 200
  76736 302
  19872 404
   6123 304
    592 403
    171 499
     95 206

获取符合状态码的地址

上例显示有19724次404请求，接下来是如何找到这些请求的URL

awk '($9 ~ /404/)' access.log | awk '{print $7}' | sort | uniq -c | sort -rn

输出如下：

9316 /
346  /Public/Home/js/jquery-2.1.1.min.js
191  /js/sucaijiayuan.js
177  /Templets/js/zh_news.js
176  /popups/popups.js
140  /images/tell_3.jpg

找出请求的ip地址

awk -F\" '($2 ~ "phpmyadmin"){print $1}' www_access.log | awk '{print $1}' | sort | uniq -c | sort -rn

输出如下：

59 180.97.106.37
34 180.97.106.162
28 180.97.106.161

php后缀的404请求

通常是扫描，测试路径。

awk '($9 ~ /404/)' access.log | awk -F\" '($2 ~ "^GET .*\.php")' | awk '{print $7}' | sort | uniq -c | sort -r | head -n 20

输出如下：

29 http://testp1.piwo.pila.pl/testproxy.php
26 http://testp3.pospr.waw.pl/testproxy.php
23 http://testp4.pospr.waw.pl/testproxy.php
17 /phpMyAdmin

按URL的请求数排序

查看前20个访问最高的URL

awk -F\" '{print $2}' access.log | awk '{print $2}' | sort | uniq -c | sort -rn | head -n 20

URL中含有phpmyadmin的URL

awk -F\" '($2 ~ "phpmyadmin"){print $2}' access.log | awk '{print $2}' | sort | uniq -c | sort -rn
